# GCP Chicago Salaries Optimization Project

A data engineering project leveraging Google Cloud Platform (GCP) to build an end-to-end data pipeline. The project utilizes public salary data from the City of Chicago to demonstrate data ingestion, storage, transformation, and optimization using SQL and Python.

![Dashboard Preview](Chicago_Salaries.png)

## ğŸ“ Dataset

- **Source**: [City of Chicago Salaries](https://data.cityofchicago.org/)
- **File**: `chicago_salaries.csv`
- **Rows**: 32,151+
- **Columns**: Name, Job Title, Department, Full/Part-Time, Salary/Hourly, Hours, Salary, Hourly Rate

---

## ğŸš€ Project Workflow

1. **Data Ingestion**
   - Python script to download and upload CSV to Google Cloud Storage (GCS)
2. **Load to BigQuery**
   - CLI command to load data from GCS to BigQuery
3. **SQL Data Transformation & Optimization**
   - Applied transformations and aggregated metrics using optimized SQL queries
4. **Scheduled Queries**
   - Created a scheduled query to run daily summary exports
5. **Export to GCS**
   - Exported the processed BigQuery table back to GCS

---

## ğŸ”§ Technologies Used

- **Cloud**: Google Cloud Platform (GCS, BigQuery)
- **Language**: Python
- **SQL**: BigQuery Standard SQL
- **Visualization**: Looker Studio (Optional)
- **Tools**: Google Cloud CLI, Git, GitHub

---

## ğŸ“Š SQL Queries Used

- Average salary by department  
- Top 10 highest-paid job titles  
- Filter employees working > 40 hours/week  
- Convert hourly rates to annual salary  
- Full-time vs part-time employee count  

> All SQL scripts are available in [`sql_scripts`](./sql_scripts) folder

---
## ğŸ“‚ Project Structure

```bash
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ pipeline_diagram.png
â”‚   â””â”€â”€ dashboard.png  # Optional: Looker Studio Screenshot
â”œâ”€â”€ data/
â”‚   â””â”€â”€ chicago_salaries.csv
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ upload_to_gcs.py
â”‚   â”œâ”€â”€ load_to_bigquery.py
â”‚   â””â”€â”€ extract_from_bigquery.py
â”œâ”€â”€ sql_queries/
â”‚   â”œâ”€â”€ avg_salary_by_department.sql
â”‚   â”œâ”€â”€ top_10_job_titles.sql
â”‚   â”œâ”€â”€ filter_40_hours.sql
â”‚   â”œâ”€â”€ convert_hourly_to_annual.sql
â”‚   â”œâ”€â”€ fulltime_vs_parttime.sql
â”‚   â””â”€â”€ scheduled_export.sql
â””â”€â”€ README.md

---

## ğŸ Python Scripts

- [`upload_to_gcs.py`](./python_scripts/upload_to_gcs.py): Uploads local CSV to GCS  
- [`load_to_bigquery.py`](./python_scripts/load_to_bigquery.py): Loads GCS CSV into BigQuery  
- [`export_from_bigquery.py`](./python_scripts/export_from_bigquery.py): Exports BigQuery table to GCS

---

## ğŸ“ How to Reproduce

1. Clone this repo  
2. Update GCP bucket/table names in Python scripts
   upload_to_gcs.py â†’ load_to_bigquery.py â†’ extract_from_bigquery.py 
4. Run the Python scripts step-by-step  
5. Use provided SQL queries for transformations  
6. Export and visualize

---
##  Project Outcomes
Successfully built an end-to-end batch data pipeline on GCP

Applied SQL optimization techniques (filter pushdown, aggregation, calculated fields)

Automated export via Scheduled Queries

Produced a clean, insightful summary of public employee salaries

----
## ğŸ“¬ Author

**Vijay More**  
GCP Data Engineer  
ğŸ“§ vijaymore300793@gmail.com  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/morevijay-dataengineer)

---

## â­ï¸ Star this Repo

If you found this helpful, feel free to star â­ this repository and share it with your network.

